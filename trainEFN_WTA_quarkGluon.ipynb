{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188e0b3e-3155-4ae7-9d3b-c42a6fd08272",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from nnTrain import train_efn, train_pfn, get_data, get_data_softDrop\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from multiprocessing import Process\n",
    "from tensorflow import keras\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from energyflow.utils import data_split, to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "# define rng seeds for train/test/val split for replicable results\n",
    "rng1 = 45446\n",
    "rng2 = 25135"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0329c3-cd54-4757-9881-bf7c958fc515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import energyflow as ef\n",
    "ef.__file__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff137cf9-20a3-4095-8224-1bb2ff5817f7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Hadron Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e91baf-ea74-44bb-a285-7013088a87be",
   "metadata": {},
   "outputs": [],
   "source": [
    "base=\"/uscms/home/sbrightt/nobackup/jets-ml/datasets/safeIncalculable_v2/\"\n",
    "nmax = 200000\n",
    "\n",
    "hdata = get_data('q',hlevel=True,efrac=True,base=base,nmax=nmax,wta=True)\n",
    "htrain, htest = train_test_split(hdata,train_size=0.5,random_state=rng1)\n",
    "htest, hval = train_test_split(htest,train_size=0.5,random_state=rng2)\n",
    "\n",
    "pdata = get_data('g',hlevel=True,efrac=True,base=base,nmax=nmax,wta=True)\n",
    "ptrain, ptest = train_test_split(pdata,train_size=0.5,random_state=rng1)\n",
    "ptest, pval = train_test_split(ptest,train_size=0.5,random_state=rng2)\n",
    "\n",
    "train = np.concatenate((htrain,ptrain),axis=0)\n",
    "train_labels = np.concatenate((np.ones((htrain.shape[0],1)),np.zeros((ptrain.shape[0],1))),axis=0)\n",
    "perm = np.random.permutation(train.shape[0])\n",
    "train = train[perm]\n",
    "train_labels = train_labels[perm]\n",
    "\n",
    "test = np.concatenate((htest,ptest),axis=0)\n",
    "test_labels = np.concatenate((np.ones((htest.shape[0],1)),np.zeros((ptest.shape[0],1))),axis=0)\n",
    "perm = np.random.permutation(test.shape[0])\n",
    "test = test[perm]\n",
    "test_labels = test_labels[perm]\n",
    "\n",
    "val = np.concatenate((hval,pval),axis=0)\n",
    "val_labels = np.concatenate((np.ones((hval.shape[0],1)),np.zeros((pval.shape[0],1))),axis=0)\n",
    "perm = np.random.permutation(val.shape[0])\n",
    "val = val[perm]\n",
    "val_labels = val_labels[perm]\n",
    "\n",
    "del hdata, pdata, htrain, htest, hval, ptrain, ptest, pval, perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e76766-c1d6-4f02-a4ea-c4abee7a2640",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# spectral EFN\n",
    "L = 200.0\n",
    "loss = BinaryCrossentropy(from_logits=True)\n",
    "#out_act = keras.activations.linear\n",
    "model_kwargs = {\"Phi_sizes\":(100,100,128), \"F_sizes\":(100,100,100),\n",
    "                \"F_acts\":\"relu\",\"Phi_acts\":\"relu\",\n",
    "                \"F_dropouts\":0.1,\n",
    "                \"input_dim\":2,\n",
    "                \"output_dim\":1,\n",
    "                \"output_act\":\"linear\",\n",
    "                \"patience\":5,\n",
    "                \"optimizer\":Adam(1e-3),\n",
    "                \"loss\":loss,\n",
    "                \"summary\":True}\n",
    "model_kwargs['spectral'] = True\n",
    "model_kwargs['lip_const'] = float(L)\n",
    "model_kwargs['eps_bjorck'] = None\n",
    "model_kwargs['bound_only'] = True\n",
    "train_kwargs = {\"epochs\":200,\"verbose\":1,\"batch_size\":10000}\n",
    "efn, auc, efn_fp, efn_tp, threshs = train_efn((train,train_labels),\n",
    "                                              (test,test_labels),\n",
    "                                              (val,val_labels),\n",
    "                                              model_kwargs,\n",
    "                                              train_kwargs,\n",
    "                                              plot=True)\n",
    "#efn.save(f\"keras_models_wta_quarkGluon/spectralEFN_L{int(L)}_zpT_hadlevel.keras\")\n",
    "del efn\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c06db7-80b1-4d82-8b07-03484d66bcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spectral EFN L >= 1\n",
    "#Ls = [20,30,40,50,60,70,80,90,\n",
    "#      100,200,300,400,500,600,700,800,900,\n",
    "#      1000,5000,10000]\n",
    "#Ls = [2000,3000,4000,6000,7000,8000,9000]\n",
    "Ls = [2,3,4,5,6,7,8,9,10]\n",
    "#for L in range(1,11,1):\n",
    "for L in Ls:\n",
    "    loss = BinaryCrossentropy(from_logits=False)\n",
    "    #out_act = keras.activations.linear\n",
    "    model_kwargs = {\"Phi_sizes\":(100,100,128), \"F_sizes\":(100,100,100),\n",
    "                    \"F_acts\":\"relu\",\"Phi_acts\":\"relu\",\n",
    "                    \"F_dropouts\":0.1,\n",
    "                    \"input_dim\":2,\n",
    "                    \"output_dim\":1,\n",
    "                    \"output_act\":\"sigmoid\",\n",
    "                    \"patience\":5,\n",
    "                    \"optimizer\":Adam(1e-3),\n",
    "                    \"loss\":loss,\n",
    "                    \"summary\":True}\n",
    "    model_kwargs['spectral'] = True\n",
    "    model_kwargs['lip_const'] = float(L)\n",
    "    model_kwargs['eps_bjorck'] = None\n",
    "    model_kwargs['bound_only'] = True\n",
    "    train_kwargs = {\"epochs\":200,\"verbose\":1,\"batch_size\":10000}\n",
    "    efn, auc, efn_fp, efn_tp, threshs = train_efn((train,train_labels),\n",
    "                                                  (test,test_labels),\n",
    "                                                  (val,val_labels),\n",
    "                                                  model_kwargs,\n",
    "                                                  train_kwargs,\n",
    "                                                  plot=True)\n",
    "    efn.save(f\"keras_models_wta_quarkGluon/spectralEFN_L{int(L)}_zpT_hadlevel.keras\")\n",
    "    del efn\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cef7fe2-50f1-4efa-a045-97aeca026ac4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# EFN without spectral normalization\n",
    "loss = BinaryCrossentropy(from_logits=False)\n",
    "#out_act = keras.activations.linear\n",
    "model_kwargs = {\"Phi_sizes\":(60,60,60), \"F_sizes\":(80,80,80),\n",
    "                \"F_dropouts\":0.1,\n",
    "                \"input_dim\":2,\n",
    "                \"output_dim\":1,\"output_act\":\"sigmoid\",\n",
    "                \"patience\":5,\n",
    "                \"optimizer\":Adam(1e-3),\n",
    "                \"loss\":loss,\n",
    "                \"summary\":True}\n",
    "model_kwargs['spectral'] = False\n",
    "train_kwargs = {\"epochs\":200,\"verbose\":1,\"batch_size\":10000}\n",
    "efn, auc, efn_fp, efn_tp, threshs = train_efn((train,train_labels),\n",
    "                                              (test,test_labels),\n",
    "                                              (val,val_labels),\n",
    "                                              model_kwargs,\n",
    "                                              train_kwargs,\n",
    "                                              plot=True)\n",
    "efn.save(f\"keras_models_wta_quarkGluon/EFN_zpT_hadlevel.keras\")\n",
    "del efn\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ae12dc-b77f-465b-9d78-8ebf3effb3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PFN without spectral normalization\n",
    "loss = BinaryCrossentropy(from_logits=False)\n",
    "#out_act = keras.activations.linear\n",
    "model_kwargs = {\"Phi_sizes\":(60,60,60), \"F_sizes\":(80,80,80),\n",
    "                \"F_dropouts\":0.1,\n",
    "                \"input_dim\":3,\n",
    "                \"output_dim\":1,\"output_act\":\"sigmoid\",\n",
    "                \"patience\":5,\n",
    "                \"optimizer\":Adam(1e-3),\n",
    "                \"loss\":loss,\n",
    "                \"summary\":True}\n",
    "model_kwargs['spectral'] = False\n",
    "train_kwargs = {\"epochs\":200,\"verbose\":1,\"batch_size\":10000}\n",
    "efn, auc, efn_fp, efn_tp, threshs = train_pfn((train,train_labels),\n",
    "                                              (test,test_labels),\n",
    "                                              (val,val_labels),\n",
    "                                              model_kwargs,\n",
    "                                              train_kwargs,\n",
    "                                              plot=True)\n",
    "efn.save(f\"keras_models_wta_quarkGluon/PFN_zpT_hadlevel.keras\")\n",
    "del efn\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59de67a-1790-4a35-bf1a-0a0569450ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PFN with spectral normalization\n",
    "L = 1\n",
    "loss = BinaryCrossentropy(from_logits=False)\n",
    "#out_act = keras.activations.linear\n",
    "model_kwargs = {\"Phi_sizes\":(60,60,60), \"F_sizes\":(80,80,80),\n",
    "                \"F_dropouts\":0.1,\n",
    "                \"input_dim\":3,\n",
    "                \"output_dim\":1,\"output_act\":\"sigmoid\",\n",
    "                \"patience\":5,\n",
    "                \"optimizer\":Adam(1e-3),\n",
    "                \"loss\":loss,\n",
    "                \"summary\":True}\n",
    "model_kwargs['spectral'] = True\n",
    "model_kwargs['lip_const'] = float(L)\n",
    "model_kwargs['eps_bjorck'] = None\n",
    "model_kwargs['bound_only'] = True\n",
    "train_kwargs = {\"epochs\":200,\"verbose\":1,\"batch_size\":10000}\n",
    "efn, auc, efn_fp, efn_tp, threshs = train_pfn((train,train_labels),\n",
    "                                              (test,test_labels),\n",
    "                                              (val,val_labels),\n",
    "                                              model_kwargs,\n",
    "                                              train_kwargs,\n",
    "                                              plot=True)\n",
    "efn.save(f\"keras_models_wta_quarkGluon/spectralPFN_L{L}_zpT_hadlevel.keras\")\n",
    "del efn\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96078ed0-8361-430a-ab7c-5cd28cb428c4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Parton Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5589530b-050e-4e0d-a14e-f109def47d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base=\"/uscms/home/sbrightt/nobackup/jets-ml/datasets/safeIncalculable_v2/\"\n",
    "nmax = 200000\n",
    "\n",
    "hdata = get_data('q',hlevel=False,efrac=True,base=base,nmax=nmax,wta=True)\n",
    "htrain, htest = train_test_split(hdata,train_size=0.5,random_state=rng1)\n",
    "htest, hval = train_test_split(htest,train_size=0.5,random_state=rng2)\n",
    "\n",
    "pdata = get_data('g',hlevel=False,efrac=True,base=base,nmax=nmax,wta=True)\n",
    "ptrain, ptest = train_test_split(pdata,train_size=0.5,random_state=rng1)\n",
    "ptest, pval = train_test_split(ptest,train_size=0.5,random_state=rng2)\n",
    "\n",
    "train = np.concatenate((htrain,ptrain),axis=0)\n",
    "train_labels = np.concatenate((np.ones((htrain.shape[0],1)),np.zeros((ptrain.shape[0],1))),axis=0)\n",
    "perm = np.random.permutation(train.shape[0])\n",
    "train = train[perm]\n",
    "train_labels = train_labels[perm]\n",
    "\n",
    "test = np.concatenate((htest,ptest),axis=0)\n",
    "test_labels = np.concatenate((np.ones((htest.shape[0],1)),np.zeros((ptest.shape[0],1))),axis=0)\n",
    "perm = np.random.permutation(test.shape[0])\n",
    "test = test[perm]\n",
    "test_labels = test_labels[perm]\n",
    "\n",
    "val = np.concatenate((hval,pval),axis=0)\n",
    "val_labels = np.concatenate((np.ones((hval.shape[0],1)),np.zeros((pval.shape[0],1))),axis=0)\n",
    "perm = np.random.permutation(val.shape[0])\n",
    "val = val[perm]\n",
    "val_labels = val_labels[perm]\n",
    "\n",
    "del hdata, pdata, htrain, htest, hval, ptrain, ptest, pval, perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bd1ea5-485b-4ecc-8172-ab2a042b981c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EFN with spectral normalization\n",
    "for i in range(1):\n",
    "    loss = BinaryCrossentropy(from_logits=False)\n",
    "    #out_act = keras.activations.linear\n",
    "    model_kwargs = {\"Phi_sizes\":(60,60,60), \"F_sizes\":(80,80,80),\n",
    "                    \"F_dropouts\":0.1,\n",
    "                    \"input_dim\":2,\n",
    "                    \"output_dim\":1,\"output_act\":\"sigmoid\",\n",
    "                    \"patience\":5,\n",
    "                    \"optimizer\":Adam(1e-4),\n",
    "                    \"loss\":loss,\n",
    "                    \"summary\":True}\n",
    "    model_kwargs['spectral'] = True\n",
    "    train_kwargs = {\"epochs\":200,\"verbose\":1,\"batch_size\":10000}\n",
    "    efn, auc, efn_fp, efn_tp, threshs = train_efn((train,train_labels),\n",
    "                                                  (test,test_labels),\n",
    "                                                  (val,val_labels),\n",
    "                                                  model_kwargs,\n",
    "                                                  train_kwargs,\n",
    "                                                  plot=True)\n",
    "    efn.save(f\"keras_models_wta_quarkGluon/spectralEFN_zpT_partlevel_iter{i}.keras\")\n",
    "    del efn\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa0030e-3df6-49c5-84d0-7eecd58adbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spectral EFN L >= 1\n",
    "#Ls = [20,30,40,50,60,70,80,90,\n",
    "#      100,200,300,400,500,600,700,800,900,\n",
    "#      1000,2000,3000,4000,5000,6000,7000,8000,9000,10000]\n",
    "Ls = [2,3,4,5,6,7,8,9,10]\n",
    "#for L in range(1,11,1):\n",
    "for L in Ls:\n",
    "    loss = BinaryCrossentropy(from_logits=False)\n",
    "    #out_act = keras.activations.linear\n",
    "    model_kwargs = {\"Phi_sizes\":(100,100,128), \"F_sizes\":(100,100,100),\n",
    "                    \"F_acts\":\"relu\",\"Phi_acts\":\"relu\",\n",
    "                    \"F_dropouts\":0.1,\n",
    "                    \"input_dim\":2,\n",
    "                    \"output_dim\":1,\n",
    "                    \"output_act\":\"sigmoid\",\n",
    "                    \"patience\":5,\n",
    "                    \"optimizer\":Adam(1e-3),\n",
    "                    \"loss\":loss,\n",
    "                    \"summary\":True}\n",
    "    model_kwargs['spectral'] = True\n",
    "    model_kwargs['lip_const'] = float(L)\n",
    "    model_kwargs['eps_bjorck'] = None\n",
    "    model_kwargs['bound_only'] = True\n",
    "    train_kwargs = {\"epochs\":200,\"verbose\":1,\"batch_size\":10000}\n",
    "    efn, auc, efn_fp, efn_tp, threshs = train_efn((train,train_labels),\n",
    "                                                  (test,test_labels),\n",
    "                                                  (val,val_labels),\n",
    "                                                  model_kwargs,\n",
    "                                                  train_kwargs,\n",
    "                                                  plot=True)\n",
    "    efn.save(f\"keras_models_wta_quarkGluon/spectralEFN_L{int(L)}_zpT_partlevel.keras\")\n",
    "    del efn\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef7c13e-9ed1-48ce-83cd-acf33424631d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EFN without spectral normalization\n",
    "loss = BinaryCrossentropy(from_logits=False)\n",
    "#out_act = keras.activations.linear\n",
    "model_kwargs = {\"Phi_sizes\":(60,60,60), \"F_sizes\":(80,80,80),\n",
    "                \"F_dropouts\":0.1,\n",
    "                \"input_dim\":2,\n",
    "                \"output_dim\":1,\"output_act\":\"sigmoid\",\n",
    "                \"patience\":5,\n",
    "                \"optimizer\":Adam(1e-3),\n",
    "                \"loss\":loss,\n",
    "                \"summary\":True}\n",
    "model_kwargs['spectral'] = False\n",
    "train_kwargs = {\"epochs\":200,\"verbose\":1,\"batch_size\":10000}\n",
    "efn, auc, efn_fp, efn_tp, threshs = train_efn((train,train_labels),\n",
    "                                              (test,test_labels),\n",
    "                                              (val,val_labels),\n",
    "                                              model_kwargs,\n",
    "                                              train_kwargs,\n",
    "                                              plot=True)\n",
    "efn.save(f\"keras_models_wta_quarkGluon/EFN_zpT_partlevel.keras\")\n",
    "del efn\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac623a2-f14b-4721-8e1e-e64ad21d314e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PFN without spectral normalization\n",
    "loss = BinaryCrossentropy(from_logits=False)\n",
    "#out_act = keras.activations.linear\n",
    "model_kwargs = {\"Phi_sizes\":(60,60,60), \"F_sizes\":(80,80,80),\n",
    "                \"F_dropouts\":0.1,\n",
    "                \"input_dim\":3,\n",
    "                \"output_dim\":1,\"output_act\":\"sigmoid\",\n",
    "                \"patience\":5,\n",
    "                \"optimizer\":Adam(1e-3),\n",
    "                \"loss\":loss,\n",
    "                \"summary\":True}\n",
    "model_kwargs['spectral'] = False\n",
    "train_kwargs = {\"epochs\":200,\"verbose\":1,\"batch_size\":10000}\n",
    "efn, auc, efn_fp, efn_tp, threshs = train_pfn((train,train_labels),\n",
    "                                              (test,test_labels),\n",
    "                                              (val,val_labels),\n",
    "                                              model_kwargs,\n",
    "                                              train_kwargs,\n",
    "                                              plot=True)\n",
    "efn.save(f\"keras_models_wta_quarkGluon/PFN_zpT_partlevel.keras\")\n",
    "del efn\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c765a7-282f-47df-9df2-cad9d212822c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PFN with spectral normalization\n",
    "L = 1\n",
    "loss = BinaryCrossentropy(from_logits=False)\n",
    "#out_act = keras.activations.linear\n",
    "model_kwargs = {\"Phi_sizes\":(60,60,60), \"F_sizes\":(80,80,80),\n",
    "                \"F_dropouts\":0.1,\n",
    "                \"input_dim\":3,\n",
    "                \"output_dim\":1,\"output_act\":\"sigmoid\",\n",
    "                \"patience\":5,\n",
    "                \"optimizer\":Adam(1e-3),\n",
    "                \"loss\":loss,\n",
    "                \"summary\":True}\n",
    "model_kwargs['spectral'] = True\n",
    "model_kwargs['lip_const'] = float(L)\n",
    "model_kwargs['eps_bjorck'] = None\n",
    "model_kwargs['bound_only'] = True\n",
    "train_kwargs = {\"epochs\":200,\"verbose\":1,\"batch_size\":10000}\n",
    "efn, auc, efn_fp, efn_tp, threshs = train_pfn((train,train_labels),\n",
    "                                              (test,test_labels),\n",
    "                                              (val,val_labels),\n",
    "                                              model_kwargs,\n",
    "                                              train_kwargs,\n",
    "                                              plot=True)\n",
    "efn.save(f\"keras_models_wta_quarkGluon/spectralPFN_L{L}_zpT_partlevel.keras\")\n",
    "del efn\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508323a4-b586-4bd4-9a1d-1f33a0e1c3d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0902795-a219-473f-95b3-2d38c51657aa",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb24ea4b-da13-4d55-abfd-10bceba9dc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "base = \"/uscms/home/sbrightt/nobackup/jets-ml/datasets/safeIncalculable/\"\n",
    "with h5py.File(base+\"h2qq_WTA_testSet_inputs_v2_pTinclusive_R1.0.h5\",\"r\") as f:\n",
    "    zq = f['test'][:,:,:1]\n",
    "    phat_q = f['test'][:,:,1:]\n",
    "    label_q = f['labels'][()][:,0]\n",
    "\n",
    "with h5py.File(base+\"h2gg_WTA_testSet_inputs_v2_pTinclusive_R1.0.h5\",\"r\") as f:\n",
    "    zg = f['test'][:,:,:1]\n",
    "    phat_g = f['test'][:,:,1:]\n",
    "    label_g = f['labels'][()][:,0]\n",
    "\n",
    "zq_part = zq[label_q==0]\n",
    "phat_q_part = phat_q[label_q==0]\n",
    "zq_had = zq[label_q==1]\n",
    "phat_q_had = phat_q[label_q==1]\n",
    "\n",
    "zg_part = zg[label_g==0]\n",
    "phat_g_part = phat_g[label_g==0]\n",
    "zg_had = zg[label_g==1]\n",
    "phat_g_had = phat_g[label_g==1]\n",
    "\n",
    "z_part = np.concatenate((zq_part,zg_part),axis=0)\n",
    "phat_part = np.concatenate((phat_q_part,phat_g_part),axis=0)\n",
    "labels_part = np.concatenate((np.ones(zq_part.shape[0]),np.zeros(zg_part.shape[0])),axis=0)\n",
    "\n",
    "z_had = np.concatenate((zq_had,zg_had),axis=0)\n",
    "phat_had = np.concatenate((phat_q_had,phat_g_had),axis=0)\n",
    "labels_had = np.concatenate((np.ones(zq_had.shape[0]),np.zeros(zg_had.shape[0])),axis=0)\n",
    "\n",
    "def eval_model(modName,z,p,path=\"keras_models_wta_quarkGluon/\",bs=1000):\n",
    "    mod = keras.models.load_model(path+\"/\"+modName)\n",
    "    if \"PFN\" in modName:\n",
    "        preds = mod.predict(np.concatenate([z,p],axis=-1),batch_size=bs)[:,0]\n",
    "    else:\n",
    "        preds = mod.predict([z,p],batch_size=bs)[:,0]\n",
    "    del mod\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcdd203-fb93-4240-b160-8bc454522bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"keras_models_wta_quarkGluon/\"\n",
    "Ls = [2,3,4,5,6,7,8,9,10,20,30,40,50,60,70,80,90,100,200,300,400,500,600,700,800,900,1000,2000,3000,4000,5000,6000,7000,8000,9000,10000]\n",
    "models_hadlevel = [\"EFN_zpT_hadlevel.keras\",\"PFN_zpT_hadlevel.keras\",\"spectralEFN_L1_zpT_hadlevel.keras\",\"spectralPFN_L1_zpT_hadlevel.keras\"]+ \\\n",
    "                  [f\"spectralEFN_L{L}_zpT_hadlevel.keras\" for L in Ls]\n",
    "models_partlevel = [\"EFN_zpT_partlevel.keras\",\"PFN_zpT_partlevel.keras\",\"spectralEFN_L1_zpT_partlevel.keras\",\"spectralPFN_L1_zpT_partlevel.keras\"]+ \\\n",
    "                   [f\"spectralEFN_L{L}_zpT_partlevel.keras\" for L in Ls]\n",
    "modKeys = [\"EFN\",\"PFN\",\"spectralEFN\",\"spectralPFN\"] + [f\"spectralEFN_L{L}\" for L in Ls]\n",
    "\n",
    "# eval had-level models on had-level data\n",
    "print(\"evaluating hadron-level models on hadron-level data\")\n",
    "np.save(f\"{base}/evaluations/labels_had.npy\",labels_had)\n",
    "for i,mod in enumerate(models_hadlevel):\n",
    "    preds = eval_model(mod,z_had,phat_had,path=base)\n",
    "    np.save(f\"{base}/evaluations/preds_hadData_hadModel_{modKeys[i]}.npy\",preds)\n",
    "    del preds\n",
    "\n",
    "# eval part-level models on part-level data\n",
    "print(\"evaluating parton-level models on parton-level data\")\n",
    "np.save(f\"{base}/evaluations/labels_part.npy\",labels_part)\n",
    "for i,mod in enumerate(models_partlevel):\n",
    "    preds = eval_model(mod,z_part,phat_part,path=base)\n",
    "    np.save(f\"{base}/evaluations/preds_partData_partModel_{modKeys[i]}.npy\",preds)\n",
    "    del preds\n",
    "\n",
    "# eval part-level models on had-level data\n",
    "print(\"evaluating parton-level models on hadron-level data\")\n",
    "for i,mod in enumerate(models_partlevel):\n",
    "    preds = eval_model(mod,z_had,phat_had,path=base)\n",
    "    np.save(f\"{base}/evaluations/preds_hadData_partModel_{modKeys[i]}.npy\",preds)\n",
    "    del preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06619a5-ab32-4521-b6fd-75fd49abf811",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-eflow]",
   "language": "python",
   "name": "conda-env-.conda-eflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
